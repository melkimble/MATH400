This problem focuses on the collinearity problem.

```{r}
LibraryList<-c("tidyverse", "broom", "ggplot2","modelr")
for (TheLibrary in LibraryList)
{
  if(TheLibrary %in% rownames(installed.packages()) == FALSE) install.packages(TheLibrary)
}
library(tidyverse)
library(broom)
library(ggplot2)
library(modelr)
set.seed(1)  # make sure everybody will have the same "random" numbers
x1 <- runif(100)
x2 <- 0.5 * x1 + rnorm(100) / 10
y <- 2 + 2 * x1 + rnorm(100)
collinearity <- tibble(x1 = x1, x2 = x2, y = y)
```

(a) Use the function `cor` to compute the sample correction between `x1` and `x2`.
```{r}
cor(x1, x2)

```

(b) Using this data, fit a least squares regression to predict `y` using `x1` and `x2`. Describe the results obtained. How do estimated coefficients relate to the true coefficients?

What's interesting is that `y`, `x1`, and `x2` independently have slopes of essentially 0. In the model, the estimated coefficients are significant and positive. I would expect `x1` to be significant because the value of `y` is dependent on the value of `x1`. `x2` has inflated significance because it is correlated with `x1`, but is not the variable that has any explanatory weight in the model.

```{r}


(fit0<-lm(y~x1+x2))

par(mfrow=c(1,3))
plot(x1)
plot(x2)
plot(y)
summary(fit0)$coefficients


```

(c) Now fit a least squares regression to predict `y` using only `x1`. Comment on your results.

Using just `x1` resulted in a positive increase in slope, which subsequently increased the significance of `x1` because the model was being negatively impacted by `x1`'s correlation with `x2`.

```{r}

(fit1<-lm(y~x1))
summary(fit1)$coefficients
ggplot(collinearity, aes(y = y, x = x1)) + geom_point() +
  geom_smooth(method = "lm", formula = y ~ x)


```

d) Which model, part (b) or part (c), give a smaller prediction error? Use a test set to check it.

With a randomly generated dataset, the model in (b) performs better than (c), but with a subset of the original dataset, (c) has a slightly better performance. Overall, the difference was very small between the two models.

```{r}
set.seed(2) 
new_data <- tibble(y = 2 + 2 * x1 + rnorm(100))
c(mse(fit0, new_data), mse(fit1, new_data))


rp <- resample_partition(collinearity, c(train = 0.7, test = 0.3))
training_set <- as.tibble(rp$train)
testing_set <- as.tibble(rp$test)

c(mse(fit0, testing_set), mse(fit1, testing_set))


```